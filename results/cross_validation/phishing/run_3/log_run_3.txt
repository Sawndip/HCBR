# Loading the instance files...
# Perform sanity checks on the dataset
# Setting the parameters...
# Initialize...
# Online: 1
# Verbose level: 0
# Cases: 11055
# Total features: 331650
# Unique features: 814 (ratio: 0.00245439)
# Minimum case size: 30
# Maximum case size: 30
# Average case size: 30
# Add cases...
# Model serialization...
# Saving the [9950,734] weight matrix...
# Calculate intrinsic strength...
Calculate strength for 9950
Serialization of pre-training strength vectors...
0.00387751 
0.00202016 
0.000190248 
0.00709451 
0.00745688 
0.000409838 
0.0136712 
3.90782e-07 
0.00317379 
0.00893394 
0.00973372 
0.0535041 
0.000824415 
0.00366687 
0.00323727 
0.000293428 
0.0106974 
0.00133522 
8.47771e-06 
0.000479025 
0.043182 
0.0688598 
0.000883148 
4.88953e-05 
0.00788494 
0.00580743 
0.00913073 
0.000557808 
0.015193 
0.00246501 
0.0101098 
0.00123055 
0.000454331 
0.000896729 
0.00556206 
0.00427385 
0.00497712 
0.00149003 
0.00119278 
4.12071e-05 
0.00307283 
7.86691e-05 
0.0162235 
0.000548131 
1.32197e-05 
1.25202e-05 
0.00319229 
8.5589e-05 
0.000113533 
0.000873419 
0.00537315 
0.0314635 
0.0250546 
0.02318 
0.00888206 
0.00903735 
0.000337535 
0.00292436 
0.011876 
0.00820581 
0.00160791 
0.00863394 
0.00680137 
1.91143e-05 
0.00034384 
0.000180221 
0.0634556 
0.00053246 
0.000117809 
0.000306396 
0.00138321 
0.000128324 
0.00109744 
0.00114247 
0.0181116 
0.00516428 
0.00167549 
0.00945261 
0.00218152 
0 
4.79725e-05 
7.56652e-05 
0.00821161 
2.5681e-05 
0.00310486 
0.000152965 
0.00162912 
0.00122445 
9.11669e-07 
0.00336831 
0.00261485 
0.00212846 
0.000814544 
0.00123646 
0.00316002 
0.000753755 
0.00173468 
0.000637752 
0.00243866 
0.000107483 
0.000352881 
0.00111518 
0.0029561 
0.000104864 
0.000955135 
0.00118396 
0.000815923 
0.000258672 
0.00268264 
0.000652753 
0.00173184 
0.00206063 
0.00422667 
0.000260237 
0.00342811 
0.00148543 
0.00151761 
0.00485563 
0.00275496 
4.09636e-05 
0.00352179 
3.65192e-06 
0.00229322 
0.00485444 
4.8511e-05 
0.000505629 
0.000436126 
0.000864151 
0.00622128 
0.00469444 
0.000956061 
0.00211261 
0.00237021 
0.0100252 
0.000153072 
0.000478807 
0.000147507 
9.07305e-05 
4.59921e-05 
2.80652e-05 
0.00880282 
0.000315616 
0.00590564 
0.00170636 
0.00051229 
0.000948292 
0.00200119 
0.000137624 
0.00231687 
0.00408003 
0.00475609 
0 
0.000204867 
0.00374291 
0.000619027 
0.00137804 
0.00246212 
0.00222167 
0.000830179 
0.0193023 
0.0107896 
0.001546 
0.000743183 
0.000369837 
0.000452209 
0 
0.00064942 
1.85031e-06 
0.00036035 
0.00256551 
0.000324498 
0.000268257 
0.00659579 
0.00176446 
0.00180023 
9.15491e-05 
0.00162141 
0.000676976 
0.00403037 
0.00220927 
0.000230151 
0.00464081 
0.00059395 
0.000399714 
0.000290548 
0.000979117 
0.00579452 
0.000759909 
0.000724947 
4.91865e-05 
0.00475543 
0.000106146 
8.03917e-05 
0.000113698 
2.09578e-05 
0.000398674 
0 
7.21515e-06 
7.5654e-06 
0.00145746 
2.00737e-05 
4.12415e-05 
7.61261e-05 
0.000145399 
9.02366e-06 
0.00013923 
4.32491e-05 
0.000150559 
0.00148457 
0.00107372 
0.000509523 
0.00287429 
0.0003943 
0.000288113 
0.000250397 
0.00131845 
0.000105803 
0.000801129 
0.00370077 
0.00129295 
0.000678676 
7.77681e-05 
0.00071013 
1.12126e-06 
0.000462568 
3.31162e-05 
0.000221574 
0.000552228 
0.00186706 
0.000321245 
0.000160719 
0.00272561 
0.000660139 
4.85994e-05 
0.000634778 
0.00738138 
0.000980325 
0.00117252 
0.00347518 
3.80583e-06 
0.00171377 
4.25804e-05 
0.000332268 
2.04669e-05 
0.000137943 
0.00106186 
0.000139367 
0.000161133 
0.000102425 
9.67102e-05 
0.000291891 
2.6388e-06 
0.00900754 
0.00135769 
0.010362 
0.00145819 
8.20159e-05 
4.26695e-05 
0.00101118 
0.000278744 
0.000283349 
0.00852675 
0.00262003 
0.000392463 
0.000111504 
1.62254e-05 
9.86707e-08 
0.000796095 
0.000106104 
0.000218025 
4.68304e-05 
2.52036e-05 
4.19444e-06 
5.98553e-05 
0.000374719 
1.93618e-05 
0.00128874 
7.44416e-05 
0.00243289 
0.000239623 
0.000169513 
5.29405e-05 
0.000184867 
0.000478531 
0.000148559 
0.000756501 
7.44459e-05 
0.000219232 
0.000148468 
9.36249e-05 
0.000762202 
0.000483063 
0.000409332 
0.000529847 
5.83193e-05 
2.14968e-05 
0.00184496 
0.00122913 
0.00065747 
0.000321737 
0.000266883 
7.10819e-05 
1.8852e-05 
5.7573e-05 
6.09633e-05 
2.27032e-05 
9.63648e-05 
0.0018959 
0.000753155 
0.000142003 
0.000257226 
0.000610705 
0.000503558 
0.000220746 
0.000484573 
0.00293759 
0.000627577 
4.00646e-05 
0.000273504 
0.000441444 
0.000122109 
2.18371e-05 
1.80019e-06 
1.58913e-05 
0.000258062 
2.06875e-05 
1.28316e-06 
1.14844e-05 
0.00023336 
2.08081e-05 
5.16489e-06 
0.00817715 
0.000121373 
1.35396e-05 
0.00187611 
0.000195187 
0.000284768 
0.000439127 
0.000710858 
4.6184e-05 
0.00394406 
6.06557e-05 
0.0023621 
0.00041951 
6.70213e-05 
0.00014351 
0.00489045 
0.000165759 
0.000380927 
0.000195786 
0.000283753 
0.00861466 
0.00249554 
0.000131716 
8.80426e-05 
0.000296371 
0.000211731 
6.93296e-05 
0.000121932 
9.33159e-05 
1.78261e-05 
0.000152025 
3.30678e-06 
0.00207166 
0.000255405 
0.00072659 
0.000145529 
0.00170032 
0.00263298 
0.000768773 
0.00225895 
5.05592e-05 
0.0002394 
2.27617e-05 
8.6091e-07 
0.000178429 
0 
0.000690811 
0.000297843 
5.7079e-05 
8.26761e-07 
2.05639e-05 
8.15049e-05 
9.64834e-05 
5.70273e-05 
3.52873e-05 
0.000247281 
0.000373976 
0.000666518 
0.000523922 
0.000272172 
0.000479517 
2.00439e-06 
0.000390694 
1.60792e-05 
0.000204449 
0 
0.00082542 
1.84443e-06 
0.000154799 
8.79821e-05 
4.00333e-05 
0.000202619 
0.00025862 
0.000317113 
4.31709e-05 
0.000463157 
5.69436e-05 
0.000295991 
5.62166e-05 
8.4892e-06 
0.000155673 
1.09602e-06 
8.46031e-05 
0.000386665 
5.00398e-05 
1.27742e-05 
7.20833e-06 
0.000263812 
2.96169e-05 
4.36926e-05 
1.61338e-06 
1.80519e-06 
2.25797e-05 
2.85634e-05 
5.36891e-05 
2.85587e-05 
8.07187e-06 
6.23547e-05 
6.18974e-05 
0.000217363 
3.584e-06 
3.49626e-05 
4.82863e-05 
1.74813e-05 
3.19351e-06 
0.000225705 
1.44327e-06 
1.71975e-05 
5.14181e-05 
4.37232e-05 
1.86536e-06 
1.0267e-05 
4.43788e-05 
0.000613215 
0.00263054 
4.24557e-06 
3.86481e-05 
9.77144e-06 
3.13664e-05 
0.00124449 
0.000280107 
0.000388611 
9.89135e-06 
7.29508e-06 
0.000684648 
0.000160745 
3.44933e-05 
0.00010064 
1.82485e-05 
0.000105811 
0.000133682 
6.98597e-05 
0.000772706 
9.6179e-05 
2.10325e-06 
1.97701e-07 
0.000649647 
9.20925e-05 
1.27267e-05 
0.00017192 
0.000154708 
0.00264025 
5.51331e-05 
3.04187e-05 
8.80469e-05 
4.4563e-05 
4.46218e-05 
0.000124828 
7.11341e-05 
4.45229e-06 
4.00493e-08 
0 
8.55784e-05 
2.83855e-08 
2.83855e-08 
8.80252e-06 
3.7097e-05 
6.80193e-05 
1.55342e-05 
1.85745e-05 
2.88265e-05 
5.17427e-05 
2.89004e-05 
3.71129e-05 
0.000140931 
1.49343e-05 
2.06551e-05 
0 
1.80142e-05 
2.38667e-07 
1.79638e-06 
4.19666e-06 
3.88111e-07 
5.23194e-06 
2.39663e-05 
2.58621e-05 
3.93858e-05 
5.30137e-06 
9.33178e-06 
2.80396e-05 
2.86448e-05 
7.66252e-05 
8.85293e-05 
1.00799e-05 
2.31801e-07 
5.78784e-05 
1.84476e-07 
1.49315e-06 
8.05443e-05 
4.80978e-05 
3.53714e-05 
5.85529e-05 
8.17284e-06 
3.09094e-05 
3.73147e-06 
1.6325e-05 
0 
8.68738e-07 
0 
0.00844821 
0 
5.98101e-05 
0.000126735 
3.72009e-05 
9.33716e-07 
6.16137e-07 
2.21809e-05 
3.92148e-06 
1.37994e-06 
0 
2.21298e-06 
5.34786e-06 
1.13853e-06 
4.65431e-06 
1.11272e-05 
6.09667e-07 
3.15925e-06 
2.88754e-05 
3.36061e-05 
1.76341e-05 
0 
1.03159e-06 
8.82411e-06 
1.10211e-05 
4.54359e-06 
8.71941e-07 
0.000365192 
0 
0 
3.1204e-05 
3.63944e-06 
2.06159e-05 
2.44227e-05 
1.35005e-05 
1.24476e-05 
1.42122e-05 
1.94265e-06 
3.02116e-06 
1.74198e-06 
1.25657e-06 
9.62931e-05 
5.76794e-07 
1.9578e-05 
1.645e-05 
4.27713e-05 
9.59437e-06 
9.32251e-06 
1.46486e-05 
4.98578e-06 
0 
0 
8.02834e-07 
1.69495e-06 
6.91765e-06 
6.97415e-06 
3.19414e-06 
9.76302e-07 
2.28795e-06 
7.25405e-08 
2.28244e-05 
1.03018e-05 
8.96623e-07 
1.27295e-06 
0 
8.53249e-06 
3.01806e-05 
1.55436e-06 
3.40028e-07 
5.92853e-07 
4.80561e-07 
8.40775e-06 
9.0386e-07 
7.89965e-07 
5.70584e-08 
4.38464e-07 
0.000783867 
4.90567e-07 
4.10036e-06 
2.14705e-06 
8.03321e-07 
4.03739e-07 
1.88225e-07 
1.88225e-07 
9.17518e-07 
2.34413e-06 
3.35276e-05 
9.59223e-07 
9.53328e-07 
5.0108e-06 
6.02134e-07 
9.6969e-07 
6.31036e-07 
6.31036e-07 
8.27765e-05 
8.5896e-06 
3.1827e-07 
4.92606e-07 
0 
2.55758e-06 
4.9716e-07 
4.10411e-06 
2.46455e-06 
0 
2.2501e-08 
0 
3.1572e-07 
3.37102e-06 
2.59713e-06 
2.35709e-06 
1.02705e-06 
0.000481164 
0.000217337 
5.4722e-06 
4.51517e-06 
0 
3.8403e-07 
3.87711e-07 
1.07868e-07 
0 
2.08342e-05 
6.72747e-08 
3.37102e-06 
1.80607e-05 
2.48355e-06 
2.48355e-06 
3.51908e-06 
1.56409e-05 
0 
1.33523e-05 
6.94107e-07 
6.16137e-07 
0 
6.78217e-07 
1.30354e-07 
1.50685e-05 
2.5208e-05 
0.000490839 
6.16137e-07 
2.2501e-08 
2.09656e-06 
6.25636e-07 
0 
1.54359e-07 
4.35184e-06 
0.00010906 
1.86781e-06 
3.84001e-07 
7.81279e-07 
0 
2.73626e-07 
1.113e-06 
1.03679e-06 
4.40023e-07 
0 
0 
1.38178e-07 
5.47555e-06 
5.47555e-06 
1.21377e-07 
1.11102e-08 
1.41285e-06 
0 
0 
2.11381e-08 
3.76137e-08 
7.2558e-08 
6.25636e-07 
3.51387e-07 
0 
8.06654e-07 
4.7621e-08 
1.40639e-06 
7.35668e-08 
0 
2.42469e-06 
2.73626e-07 
5.55319e-07 
1.41285e-06 
7.24071e-05 
0.000221477 
3.8093e-06 
0.000813801 
1.56366e-07 
1.25147e-06 
7.9537e-07 
6.31036e-07 
1.58029e-07 
9.14413e-08 
0 
1.57072e-07 
6.16137e-07 
0 
2.50255e-06 
0 
1.4712e-07 
1.5361e-08 
0 
2.53317e-05 
4.34111e-05 
6.11605e-08 
4.51517e-06 
0 
0 
# Learning phase...
 - Before training
Accuracy: 7181/9950 = 0.721709
Average error toward 0: -0.000183598 (1779)
Average error toward 1: 7.98317e-05 (990)
Prev: 0.445226 (error: 0.178794) Offset: 0 0
Ratio error 1 : 0.35753
-----------------
- 3741 - 990 - 
-----------------
- 1779 - 3440 - 
-----------------
 - Phase 1
Accuracy: 8918/9950 = 0.896281
Average error toward 0: -0.000195 (529)
Average error toward 1: 0.000089 (503)
Prev: 0.445226 (error: 0.053166) Offset: 0.000000 0.000000
Ratio error 1 : 0.487403
-----------------
- 4991 - 503 - 
-----------------
- 529 - 3927 - 
-----------------
 - Phase 2
Accuracy: 9192/9950 = 0.923819
Average error toward 0: -0.000197 (384)
Average error toward 1: 0.000091 (374)
Prev: 0.445226 (error: 0.038593) Offset: 0.000000 0.000000
Ratio error 1 : 0.493404
-----------------
- 5136 - 374 - 
-----------------
- 384 - 4056 - 
-----------------
 - Phase 3
Accuracy: 9215/9950 = 0.926131
Average error toward 0: -0.000198 (367)
Average error toward 1: 0.000092 (368)
Prev: 0.445226 (error: 0.036884) Offset: 0.000000 0.000000
Ratio error 1 : 0.500680
-----------------
- 5153 - 368 - 
-----------------
- 367 - 4062 - 
-----------------
 - Phase 4
Accuracy: 9258/9950 = 0.930452
Average error toward 0: -0.000198 (343)
Average error toward 1: 0.000092 (349)
Prev: 0.445226 (error: 0.034472) Offset: 0.000000 0.000000
Ratio error 1 : 0.504335
-----------------
- 5177 - 349 - 
-----------------
- 343 - 4081 - 
-----------------
 - Phase 5
Accuracy: 9287/9950 = 0.933367
Average error toward 0: -0.000199 (329)
Average error toward 1: 0.000093 (334)
Prev: 0.445226 (error: 0.033065) Offset: 0.000000 0.000000
Ratio error 1 : 0.503771
-----------------
- 5191 - 334 - 
-----------------
- 329 - 4096 - 
-----------------
 - Verification
Accuracy: 9232/9950 = 0.927839
Average error toward 0: -0.000199 (583)
Average error toward 1: 0.000093 (135)
Prev: 0.445226 (error: 0.058593) Offset: 0.000000 0.000000
Ratio error 1 : 0.188022
-----------------
- 4937 - 135 - 
-----------------
- 583 - 4295 - 
-----------------
Serialization of post-training strength vectors...
# Predictions
# Already in case-base: 760 0.964474
0.885494
Accuracy: 1042/1104 = 0.943841
Average error toward 0: -0.000000 (36)
Average error toward 1: 0.000000 (26)
Prev: 0.445226 (error: 0.003618) Offset: 0.000000 0.000000
Ratio error 1 : 0.419355
-----------------
- 600 - 26 - 
-----------------
- 36 - 442 - 
-----------------
# Prediction serialization...
# Saving the [1104,734] weight matrix...
4.618304
