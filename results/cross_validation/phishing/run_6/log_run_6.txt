# Loading the instance files...
# Perform sanity checks on the dataset
# Setting the parameters...
# Initialize...
# Online: 1
# Verbose level: 0
# Cases: 11055
# Total features: 331650
# Unique features: 814 (ratio: 0.00245439)
# Minimum case size: 30
# Maximum case size: 30
# Average case size: 30
# Add cases...
# Model serialization...
# Saving the [9950,737] weight matrix...
# Calculate intrinsic strength...
Calculate strength for 9950
Serialization of pre-training strength vectors...
0.00354635 
7.6723e-05 
0.00823434 
0.001984 
0.000120051 
3.65476e-05 
0.00710598 
0.000113484 
0.00675135 
0.0233957 
7.95407e-05 
0.0529982 
0.00129027 
0.00105774 
0.000879985 
2.50515e-06 
0.00295187 
0.00843326 
0.0032701 
0.011609 
0.0151026 
0.00341366 
0.000246098 
0.0025354 
0.00142192 
0.00058266 
0.00244593 
0.0692841 
0.0104885 
0.00561738 
0.00894593 
0.0319781 
0.000871905 
2.17454e-07 
0.00138521 
0.000186193 
0.00038158 
0.00072224 
0.00814462 
0.0256313 
0.00149547 
0.00103738 
6.39497e-05 
0.00308734 
0.0440029 
1.19612e-05 
0.00827023 
0.00143859 
0.0190384 
0.000393076 
0.000215383 
0.00085208 
0.00926359 
0.0012036 
0.00248042 
0.0007082 
0.00141448 
0.003432 
0.00808201 
0.00233199 
0.000149587 
0.000481 
0.000773564 
0.00160176 
5.63115e-06 
0.000826006 
0.000316047 
0.000658701 
0.000129534 
0.000961623 
0.00305693 
0.00244861 
0.000623718 
0.000351407 
0.00464722 
0.000588095 
0.00154494 
0.00178516 
2.60784e-05 
0.00432844 
0.000717102 
0.00578139 
0.00389971 
7.10206e-05 
0.00274033 
0.000260023 
0.00214682 
0.00120399 
0.00407922 
0.00481668 
0.000674114 
0.00999781 
0.00171996 
0.000940238 
0.00297649 
7.06876e-05 
0.000896917 
0.00210453 
0.00991027 
4.05885e-07 
0.0181489 
0.00138796 
0.0104326 
0.00852664 
0.0112802 
0.00954713 
0.00170514 
0.00840024 
0.000711881 
0 
0.0037541 
0.00646645 
0.000968776 
0.000191716 
0.00724414 
0.000314547 
0.00049312 
0.0620102 
0.000309672 
0.00264993 
0.00251603 
0.00119583 
0.000122931 
0 
0.000143437 
0.00270809 
0.0134817 
0.00172358 
0.000723291 
0.000127624 
0.00879668 
0.00491936 
9.46082e-05 
0.0074528 
0.000501 
0.0012848 
0.00298589 
1.41934e-06 
0.00139874 
0.00516088 
0.002087 
0.00169261 
0.00468258 
0.000121927 
0 
0.00560302 
0.000837731 
0.00035186 
0.000702683 
9.69046e-07 
0.000557175 
0.010281 
0.000930087 
0.000525703 
4.53161e-05 
0.000455587 
0.00266893 
0.000880611 
0.000784689 
5.2892e-06 
0.000388006 
1.77168e-06 
0.000671886 
2.64204e-05 
0.00453593 
0.00103701 
0.00116166 
0.00119937 
0.0040146 
0.00514676 
3.97544e-05 
0.00208353 
0.00867399 
0.00500622 
0.000243082 
0.000123406 
0.000299637 
4.12779e-05 
5.87093e-05 
0.0061854 
0.00412244 
4.69653e-06 
0.000381344 
8.94764e-05 
0.00118318 
0.000246967 
0.000228977 
0.00195789 
0.000362105 
0.000183223 
1.34157e-05 
0.000114231 
2.73157e-05 
4.50528e-05 
0.000291398 
0.00172454 
0.000751886 
0.000857269 
0.00022157 
0.0011804 
0.000475235 
0.000510994 
0.000279 
0.000271315 
1.86835e-05 
0 
0.00013288 
1.4764e-05 
7.03089e-05 
0.000498067 
0.000302476 
0.000147964 
7.95422e-05 
0.000160857 
3.47231e-05 
0.000535805 
4.37723e-05 
8.19758e-05 
6.99054e-05 
0.00140814 
0.000357765 
0.00231523 
0.00330903 
0.00203352 
0.00186393 
0.00307207 
0.00101675 
8.60404e-05 
0.00371025 
0.000508222 
0.000269012 
0.000105997 
0.00249988 
0.000930373 
0.000276023 
0.000195934 
5.22303e-05 
0.000317099 
0.000428507 
5.0055e-05 
0.00117248 
6.5194e-06 
5.14809e-05 
0.000270216 
6.57938e-05 
1.45041e-05 
0.000281515 
2.13262e-05 
3.57432e-07 
2.21398e-06 
0.000771748 
2.11558e-05 
9.50485e-06 
0 
0.00315753 
0.000325612 
0.000298921 
0.000416498 
0.000270441 
8.85249e-05 
0.000115183 
0.000384494 
0.00014535 
0.00010258 
0.0161645 
0.000280843 
0.00887045 
0.00421925 
0.00015183 
0.000696747 
0.00268755 
0.00186508 
9.58138e-05 
0.0024334 
0.00343671 
4.28711e-05 
0.00045397 
0.000154141 
4.94742e-05 
2.64735e-05 
2.84035e-05 
4.90194e-05 
1.295e-05 
0.000100941 
3.6694e-07 
2.30974e-05 
0.000172846 
0.000397776 
0.000123514 
0 
0.00174344 
0.000189842 
0.00488153 
0.000234495 
6.53311e-05 
0.00429679 
0.00355631 
0.00015445 
0.00204394 
0.000435535 
0.000468293 
0.00596577 
0.000710221 
0.000133064 
2.06633e-05 
5.37051e-05 
0.00057766 
8.8424e-05 
0.000261847 
1.04423e-05 
0.00022634 
0.00035198 
5.08522e-05 
0 
0.000389845 
0.00148055 
0.00229896 
0.000787349 
0.000725269 
0.000444323 
0.000126976 
0.000313291 
0.000756871 
0.000446942 
0.000358311 
6.29771e-05 
0.00029211 
3.9726e-05 
0.000787681 
0.00253528 
9.76827e-06 
0.00146628 
0.000381073 
0.000572258 
2.9907e-05 
2.54796e-05 
1.15382e-05 
9.5352e-06 
0 
0.000172163 
5.69451e-06 
5.82206e-05 
9.91592e-05 
8.27785e-05 
0.00244015 
6.34727e-05 
5.25242e-05 
0.000604078 
0.0003564 
0.000285897 
0.000613254 
0.0013466 
8.67753e-05 
0.000665512 
0.000198188 
0.000292606 
4.98521e-06 
0.000141776 
0.00588095 
0.000187828 
0.000368568 
4.82781e-06 
0.00201642 
0.00023662 
0.000233391 
0.000156137 
0.000324238 
0.00187342 
0.000393843 
0.000161088 
3.19936e-05 
3.70761e-06 
0.000213967 
0.000119393 
0.000581483 
7.31527e-08 
0.000219303 
2.81089e-06 
0.000363988 
0.000599938 
0.000227297 
8.28937e-05 
8.96792e-05 
0.000657266 
5.58744e-05 
3.15765e-06 
0.00024091 
0.000135713 
0.000501433 
6.19553e-05 
0.000129345 
0.00124351 
0.000128404 
0.000953684 
0.0022441 
8.075e-05 
4.04186e-05 
8.49785e-05 
9.58674e-05 
9.70954e-05 
4.3133e-07 
0.000103857 
4.51141e-06 
2.05699e-05 
6.02968e-05 
4.7048e-08 
4.64932e-05 
4.46549e-05 
2.83183e-08 
0.000300005 
5.15566e-07 
8.53676e-05 
0.000190382 
5.15143e-05 
9.29061e-06 
0 
2.37243e-05 
1.91847e-06 
0.00052711 
4.76664e-05 
2.13564e-08 
4.46371e-05 
3.26573e-05 
2.94303e-05 
0.000329598 
2.68045e-05 
6.19856e-06 
0.000247389 
0.00249679 
0.00176156 
2.81424e-06 
0.00847017 
0.000131208 
5.27848e-05 
6.18193e-05 
1.79592e-05 
1.10587e-06 
5.82661e-05 
6.19395e-07 
1.78234e-05 
0 
8.46599e-06 
6.44772e-05 
1.71145e-06 
0.000349149 
0.000146543 
0.000757505 
0.000606107 
1.48587e-05 
4.57732e-05 
1.78076e-05 
4.21251e-05 
0.000167066 
1.94752e-05 
0 
3.79828e-08 
0.00126565 
4.45337e-05 
4.63588e-06 
5.50622e-07 
1.61907e-05 
0.000488058 
0.000111824 
3.55844e-05 
1.10208e-06 
7.63229e-05 
1.16207e-05 
0.000737206 
3.71418e-06 
1.46248e-06 
1.74708e-05 
3.69051e-06 
2.84242e-05 
0.000108461 
1.29469e-05 
4.70951e-06 
3.67918e-05 
1.72594e-06 
6.85961e-06 
5.27863e-05 
9.14945e-07 
1.09593e-06 
8.6392e-06 
0 
9.39883e-08 
7.74367e-05 
0.000219703 
8.47778e-05 
1.27898e-05 
2.60308e-05 
4.13223e-06 
1.57742e-05 
3.9678e-05 
4.40008e-05 
6.8529e-05 
2.2907e-05 
5.38457e-05 
7.70252e-05 
6.3119e-05 
3.34019e-05 
1.49861e-05 
0.000170883 
0.000136916 
5.51539e-05 
0.00016446 
1.51155e-06 
7.64095e-05 
0 
1.08762e-05 
8.92004e-06 
4.53737e-07 
7.00236e-06 
1.58964e-06 
2.77918e-05 
0 
4.86746e-05 
0.00160529 
1.18162e-05 
3.97351e-05 
3.4883e-06 
1.52507e-06 
3.64031e-05 
2.2878e-05 
6.04466e-07 
1.42988e-05 
0.000118288 
0.000225552 
3.89902e-05 
8.3997e-06 
1.89808e-06 
5.18595e-05 
1.45161e-06 
3.43129e-07 
1.35214e-06 
4.2215e-07 
2.93899e-05 
2.22959e-05 
1.16834e-05 
2.47311e-06 
7.34258e-08 
0.00897131 
8.85648e-06 
4.84578e-05 
1.56945e-05 
1.1761e-05 
1.64582e-05 
4.0501e-06 
1.9654e-05 
3.55982e-07 
2.73039e-06 
2.36217e-06 
1.84672e-06 
3.49678e-08 
2.03133e-06 
3.7039e-06 
2.72283e-07 
1.02221e-05 
9.96306e-07 
0 
0.000273356 
2.83183e-08 
4.01503e-08 
4.92338e-05 
3.9431e-05 
2.38894e-05 
2.09456e-06 
1.278e-06 
7.84767e-07 
1.2066e-06 
0.00267391 
4.72288e-05 
3.728e-06 
0 
1.25194e-05 
2.33485e-06 
5.37414e-05 
3.76963e-05 
3.30386e-07 
3.13328e-05 
8.33142e-05 
3.68625e-06 
4.06593e-05 
5.5232e-06 
8.59462e-07 
3.48689e-05 
2.78283e-05 
0 
0.000120951 
0.000752013 
3.16904e-07 
9.77414e-06 
4.05934e-07 
7.95138e-07 
1.69729e-05 
3.6953e-05 
3.11222e-06 
3.24035e-06 
2.03161e-05 
0 
2.24389e-05 
2.20231e-05 
4.20458e-05 
8.27192e-05 
0 
9.62478e-06 
1.19062e-05 
3.55982e-07 
0 
3.45031e-07 
4.64129e-07 
7.03446e-06 
2.24813e-08 
2.86982e-06 
1.20775e-05 
4.59098e-06 
4.72501e-07 
1.89582e-07 
0 
8.45087e-07 
6.08362e-07 
8.04926e-07 
1.89582e-07 
1.43094e-06 
4.43189e-07 
4.7743e-08 
1.19923e-06 
2.51907e-06 
9.04037e-06 
6.40006e-07 
1.02401e-05 
2.99866e-06 
8.83619e-07 
2.80653e-07 
3.24035e-06 
0.000437532 
6.27578e-06 
1.25113e-05 
2.49471e-07 
7.39884e-08 
6.27964e-07 
2.24813e-08 
0 
2.51889e-06 
5.12741e-06 
2.13681e-06 
9.81494e-05 
5.32313e-06 
1.94593e-06 
3.40878e-08 
5.54016e-07 
2.72283e-07 
2.39614e-07 
1.27345e-06 
2.9528e-06 
5.13221e-05 
0 
3.92215e-06 
3.16904e-07 
6.97535e-07 
1.07265e-06 
6.27578e-06 
9.82575e-08 
5.75443e-08 
1.99973e-07 
0.000439384 
0.000217311 
2.14133e-06 
1.9405e-05 
3.92215e-06 
0 
9.80458e-07 
8.19293e-06 
4.45566e-07 
1.41934e-06 
6.08484e-07 
3.04551e-06 
7.35873e-05 
0.000221462 
4.66182e-07 
0 
4.67228e-06 
9.49658e-07 
0.000817537 
1.25923e-06 
8.09137e-07 
1.9089e-05 
3.55982e-07 
1.59856e-07 
2.53594e-06 
6.27964e-07 
2.26067e-05 
6.40006e-07 
6.27964e-07 
0 
9.21208e-08 
0 
1.32065e-07 
7.33359e-07 
7.12742e-06 
2.63012e-07 
5.00099e-07 
1.59835e-07 
2.56002e-06 
0 
2.53594e-06 
6.27964e-07 
0 
1.73428e-05 
1.83812e-05 
2.24763e-06 
2.64299e-07 
1.5534e-08 
0 
4.5953e-06 
0 
2.33314e-05 
1.88512e-07 
6.12528e-08 
0 
4.5953e-06 
1.32762e-06 
0 
6.40006e-07 
0 
0 
0 
6.27964e-07 
0 
0 
6.27964e-07 
1.89073e-08 
1.57431e-07 
3.93631e-07 
0 
0 
4.35199e-05 
6.75042e-08 
# Learning phase...
 - Before training
Accuracy: 7159/9950 = 0.719497
Average error toward 0: -0.000187425 (1789)
Average error toward 1: 8.22365e-05 (1002)
Prev: 0.443719 (error: 0.179799) Offset: 0 0
Ratio error 1 : 0.359011
-----------------
- 3746 - 1002 - 
-----------------
- 1789 - 3413 - 
-----------------
 - Phase 1
Accuracy: 8925/9950 = 0.896985
Average error toward 0: -0.000199 (526)
Average error toward 1: 0.000092 (499)
Prev: 0.443719 (error: 0.052864) Offset: 0.000000 0.000000
Ratio error 1 : 0.486829
-----------------
- 5009 - 499 - 
-----------------
- 526 - 3916 - 
-----------------
 - Phase 2
Accuracy: 9213/9950 = 0.925930
Average error toward 0: -0.000201 (371)
Average error toward 1: 0.000093 (366)
Prev: 0.443719 (error: 0.037286) Offset: 0.000000 0.000000
Ratio error 1 : 0.496608
-----------------
- 5164 - 366 - 
-----------------
- 371 - 4049 - 
-----------------
 - Phase 3
Accuracy: 9234/9950 = 0.928040
Average error toward 0: -0.000202 (359)
Average error toward 1: 0.000094 (357)
Prev: 0.443719 (error: 0.036080) Offset: 0.000000 0.000000
Ratio error 1 : 0.498603
-----------------
- 5176 - 357 - 
-----------------
- 359 - 4058 - 
-----------------
 - Phase 4
Accuracy: 9255/9950 = 0.930151
Average error toward 0: -0.000202 (347)
Average error toward 1: 0.000095 (348)
Prev: 0.443719 (error: 0.034874) Offset: 0.000000 0.000000
Ratio error 1 : 0.500719
-----------------
- 5188 - 348 - 
-----------------
- 347 - 4067 - 
-----------------
 - Phase 5
Accuracy: 9270/9950 = 0.931658
Average error toward 0: -0.000203 (340)
Average error toward 1: 0.000095 (340)
Prev: 0.443719 (error: 0.034171) Offset: 0.000000 0.000000
Ratio error 1 : 0.500000
-----------------
- 5195 - 340 - 
-----------------
- 340 - 4075 - 
-----------------
 - Verification
Accuracy: 9302/9950 = 0.934874
Average error toward 0: -0.000203 (304)
Average error toward 1: 0.000095 (344)
Prev: 0.443719 (error: 0.030553) Offset: 0.000000 0.000000
Ratio error 1 : 0.530864
-----------------
- 5231 - 344 - 
-----------------
- 304 - 4071 - 
-----------------
Serialization of post-training strength vectors...
# Predictions
# Already in case-base: 751 0.977364
0.911598
Accuracy: 1056/1104 = 0.956522
Average error toward 0: -0.000000 (18)
Average error toward 1: 0.000000 (30)
Prev: 0.443719 (error: 0.001809) Offset: 0.000000 0.000000
Ratio error 1 : 0.625000
-----------------
- 604 - 30 - 
-----------------
- 18 - 452 - 
-----------------
# Prediction serialization...
# Saving the [1104,737] weight matrix...
4.561542
