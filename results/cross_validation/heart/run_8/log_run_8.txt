# Loading the instance files...
# Perform sanity checks on the dataset
# Setting the parameters...
# Initialize...
# Online: 0
# Verbose level: 0
# Cases: 270
# Total features: 3779
# Unique features: 385 (ratio: 0.101879)
# Minimum case size: 13
# Maximum case size: 14
# Average case size: 13.9963
# Add cases...
# Model serialization...
# Saving the [243,349] weight matrix...
# Calculate intrinsic strength...
Calculate strength for 243
Serialization of pre-training strength vectors...
5.49915e-05 
0.13059 
0 
0.0731434 
0.177932 
1.72031e-05 
0.0331975 
0.00482937 
0.128075 
0.00414524 
0 
0.00461476 
0.0937124 
0.0593978 
0.0192002 
0.0160982 
0.00937236 
0 
0.082986 
0.030377 
0.00527476 
0.000133433 
5.56053e-05 
0.00773337 
0 
0.000878251 
6.5674e-05 
0.0612344 
1.49279e-05 
0.0204344 
1.36509e-05 
0 
6.16045e-05 
0.00078129 
0 
0 
0.000550152 
0.00101674 
1.75289e-05 
0.00208982 
1.51975e-05 
6.29155e-05 
1.46676e-05 
0.000544375 
0 
0.000814386 
0.000235944 
0.00168597 
0 
8.7006e-05 
0.000162316 
0 
7.01022e-05 
0.000254118 
1.41518e-05 
0 
0.00259523 
0.000270933 
0.000251803 
0.000138609 
0 
0 
0.000784021 
6.42301e-05 
1.41087e-05 
0.00319437 
0.000843288 
7.18857e-05 
0.000423836 
0.000592846 
1.53998e-05 
1.50737e-05 
0 
0 
6.36006e-05 
1.77645e-05 
0 
6.43846e-05 
0 
6.10214e-05 
0.000146143 
0 
0.00158544 
1.35509e-05 
1.54255e-05 
6.17019e-05 
0 
1.86975e-05 
0 
0.000246718 
0.000247509 
0.000385173 
0 
5.86986e-05 
6.10416e-05 
5.93178e-05 
6.54083e-05 
0.000712621 
5.76855e-05 
0 
1.77645e-05 
0.000528965 
0 
0 
0.000767075 
1.64101e-05 
0.000550217 
1.64101e-05 
6.53206e-05 
1.36107e-05 
0.000131454 
6.13951e-05 
0.00023128 
1.62089e-05 
0 
1.36912e-05 
0 
0.000142011 
0.000227565 
0.000138872 
6.34765e-05 
1.37319e-05 
0.000711699 
0 
0 
0.000512744 
1.38345e-05 
1.76291e-05 
1.76291e-05 
0.000242934 
0.00013601 
0.000216536 
5.69074e-05 
0 
1.5529e-05 
1.5529e-05 
0 
0.000514541 
0 
1.45752e-05 
0 
6.17686e-05 
6.34461e-05 
0.00012787 
0 
6.90758e-05 
0 
1.55813e-05 
7.01449e-05 
6.11609e-05 
1.68892e-05 
8.13883e-05 
6.0901e-05 
0.000127338 
1.41735e-05 
1.41735e-05 
6.55915e-05 
5.95966e-05 
6.12865e-05 
1.51975e-05 
0.000151812 
1.67668e-05 
1.62089e-05 
2.03861e-05 
1.51478e-05 
6.11517e-05 
1.37523e-05 
0 
1.36107e-05 
5.87132e-05 
6.91473e-05 
0.00054526 
6.43849e-05 
1.41518e-05 
1.41952e-05 
0 
1.37523e-05 
0.000144091 
0 
0.000249905 
1.36308e-05 
1.45752e-05 
0 
0 
0 
1.45523e-05 
6.26383e-05 
6.43629e-05 
0.000381472 
1.73971e-05 
1.37319e-05 
0 
1.75289e-05 
0 
0.000153154 
1.67365e-05 
0.000383255 
5.59061e-05 
0 
6.66313e-05 
5.7481e-05 
5.73199e-05 
0 
0.000146112 
0 
0 
6.06553e-05 
0.000236026 
1.90047e-05 
0 
5.35522e-05 
0 
0 
0 
6.87337e-05 
1.39808e-05 
6.56831e-05 
0 
0.000251639 
1.36912e-05 
1.53998e-05 
0 
1.54771e-05 
1.45523e-05 
0 
0 
1.76291e-05 
0.000137174 
0 
0 
1.41952e-05 
1.83637e-05 
0 
1.42828e-05 
1.75622e-05 
6.08926e-05 
0.000146196 
0.000239279 
1.67365e-05 
0 
0.000240742 
6.0295e-05 
5.91392e-05 
0.000140372 
6.52235e-05 
1.58753e-05 
1.59574e-05 
0 
0 
0 
0 
6.59965e-05 
6.32933e-05 
5.73901e-05 
1.75622e-05 
0 
1.86223e-05 
6.27628e-05 
1.45982e-05 
7.15475e-05 
1.38345e-05 
5.71308e-05 
5.44879e-05 
1.41087e-05 
1.59849e-05 
0.000609236 
1.86598e-05 
0 
1.46676e-05 
0 
0 
1.33554e-05 
0 
1.55813e-05 
2.54966e-05 
5.44036e-05 
8.41389e-05 
6.9458e-05 
5.95844e-05 
1.46444e-05 
0 
1.75289e-05 
1.83637e-05 
5.64615e-05 
6.42033e-05 
0 
0 
0 
0 
0 
5.83046e-05 
0 
0 
0 
1.47612e-05 
0 
1.59574e-05 
0.000136182 
0 
0 
5.62631e-05 
5.86255e-05 
1.54771e-05 
6.4114e-05 
1.50983e-05 
1.51726e-05 
5.75792e-05 
0 
1.41518e-05 
0 
1.50983e-05 
1.32597e-05 
1.34524e-05 
1.5529e-05 
0 
5.39666e-05 
5.88571e-05 
1.37933e-05 
0 
1.35114e-05 
0 
6.04765e-05 
0 
6.92145e-05 
0 
1.53742e-05 
0 
6.15773e-05 
1.37933e-05 
0 
2.02967e-05 
8.11867e-05 
0 
1.37319e-05 
1.40658e-05 
0 
5.87879e-05 
1.33554e-05 
0 
0 
1.81833e-05 
6.5889e-05 
7.2733e-05 
5.96389e-05 
5.68583e-05 
1.50737e-05 
0 
0 
1.50005e-05 
# Learning phase...
 - Before training
Accuracy: 200/243 = 0.823045
Average error toward 0: -0.000567738 (23)
Average error toward 1: 0.000662059 (20)
Prev: 0.444444 (error: 0.0946502) Offset: 0 0
Ratio error 1 : 0.465116
-----------------
- 112 - 20 - 
-----------------
- 23 - 88 - 
-----------------
 - Phase 1
Accuracy: 203/243 = 0.835391
Average error toward 0: -0.000997 (21)
Average error toward 1: 0.001123 (19)
Prev: 0.444444 (error: 0.086420) Offset: 0.000000 0.000000
Ratio error 1 : 0.475000
-----------------
- 114 - 19 - 
-----------------
- 21 - 89 - 
-----------------
 - Verification
Accuracy: 205/243 = 0.843621
Average error toward 0: -0.001114 (15)
Average error toward 1: 0.001479 (23)
Prev: 0.444444 (error: 0.061728) Offset: 0.000000 0.000000
Ratio error 1 : 0.605263
-----------------
- 120 - 23 - 
-----------------
- 15 - 85 - 
-----------------
Serialization of post-training strength vectors...
# Predictions
# Already in case-base: 0 -nan
0.849662
Accuracy: 24/26 = 0.923077
Average error toward 0: 0.000000 (0)
Average error toward 1: 0.000036 (2)
Prev: 0.444444 (error: 0.000000) Offset: 0.000000 0.000000
Ratio error 1 : 1.000000
-----------------
- 15 - 2 - 
-----------------
- 0 - 9 - 
-----------------
# Prediction serialization...
# Saving the [26,349] weight matrix...
0.058297
