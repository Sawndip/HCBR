# Loading the instance files...
# Perform sanity checks on the dataset
# Setting the parameters...
# Initialize...
# Online: 0
# Verbose level: 0
# Cases: 270
# Total features: 3779
# Unique features: 385 (ratio: 0.101879)
# Minimum case size: 13
# Maximum case size: 14
# Average case size: 13.9963
# Add cases...
# Model serialization...
# Saving the [243,347] weight matrix...
# Calculate intrinsic strength...
Calculate strength for 243
Serialization of pre-training strength vectors...
0 
0.0678097 
0 
0.0761811 
0.014229 
1.37725e-05 
0.000477385 
0.0403732 
5.02494e-05 
0.0986853 
0.129268 
0.00229666 
1.25521e-05 
0.000132949 
0.0259563 
0.0188232 
0.0504907 
5.11129e-05 
1.30667e-05 
0.121594 
0.00717625 
0 
0.00177864 
0.00398703 
0.0139186 
0 
0.0752141 
5.04926e-05 
5.53461e-05 
0.00925145 
1.29717e-05 
0.00589876 
0.0190253 
0 
0.000804414 
0 
1.28226e-05 
0 
0.00206797 
0 
5.90004e-05 
1.43482e-05 
1.44177e-05 
0.000394948 
0 
0.00012739 
6.04415e-05 
0.000223788 
1.69992e-05 
5.84947e-05 
0.000541785 
6.06836e-05 
0 
0.000232289 
1.31437e-05 
0.00110053 
5.02677e-05 
0.000235229 
0.000398805 
1.42337e-05 
6.39968e-05 
6.12182e-05 
0 
0.000504049 
5.24968e-05 
1.3202e-05 
5.3269e-05 
0.000202006 
0.00111898 
5.69166e-05 
1.29717e-05 
0 
1.71957e-05 
0.181207 
1.86706e-05 
6.60376e-05 
0.00102874 
1.86706e-05 
0.000781611 
5.20884e-05 
0.00434201 
0 
1.26053e-05 
5.52643e-05 
6.06425e-05 
0.00012966 
0.000151609 
1.33004e-05 
0 
0.00145195 
0 
0.000713198 
1.2695e-05 
0 
6.21505e-05 
5.2584e-05 
0.000378791 
0.000135645 
0.000227213 
5.45295e-05 
5.25087e-05 
4.99276e-05 
6.51645e-05 
0 
0 
5.27357e-05 
1.2695e-05 
0.00011924 
5.9233e-05 
0.00024328 
1.44644e-05 
5.55371e-05 
0.000501567 
0.000228893 
0 
0.000154464 
0.0029512 
0.000344971 
1.49993e-05 
1.39229e-05 
0 
0 
0.000724974 
1.588e-05 
1.26053e-05 
5.60861e-05 
0 
1.38796e-05 
1.24994e-05 
0.00035765 
1.60803e-05 
0.00022691 
0.000662222 
6.02877e-05 
5.40402e-05 
6.11428e-05 
0.000127427 
6.10106e-05 
1.30667e-05 
1.27494e-05 
0 
0.000706234 
0.000345113 
0 
0 
0 
0.000126679 
7.36824e-05 
0.000995935 
0.000133259 
0.000136586 
1.51264e-05 
1.42565e-05 
0 
0.000131645 
6.44523e-05 
0 
5.85946e-05 
1.57957e-05 
5.37256e-05 
5.34508e-05 
0.00022075 
0 
1.39664e-05 
1.43482e-05 
0.000211727 
0 
0.000223372 
0.000123987 
0.000124747 
1.40766e-05 
0 
6.66984e-05 
6.0399e-05 
0.000233746 
1.46786e-05 
1.62857e-05 
0.000226814 
0 
0 
0 
0 
1.39664e-05 
5.13466e-05 
1.71626e-05 
1.39664e-05 
0 
0.00013304 
0.000249457 
1.59083e-05 
0.000236926 
6.60852e-05 
0 
0.000125961 
5.185e-05 
5.3952e-05 
6.44871e-05 
1.37725e-05 
1.60803e-05 
0 
0.000510874 
1.39012e-05 
1.29154e-05 
7.80238e-05 
1.56846e-05 
1.46786e-05 
0 
6.18733e-05 
6.31924e-05 
1.52296e-05 
0 
1.3202e-05 
5.28095e-05 
1.27494e-05 
0 
0.00012183 
0 
1.2695e-05 
0 
5.96592e-05 
1.34204e-05 
1.70969e-05 
0 
0 
1.35016e-05 
1.32412e-05 
6.55014e-05 
5.63099e-05 
1.43251e-05 
0 
0 
5.92011e-05 
0 
0 
1.2641e-05 
0.000132107 
1.77075e-05 
0 
5.51835e-05 
5.92011e-05 
0 
1.52818e-05 
0 
1.32216e-05 
0 
1.5521e-05 
0 
1.29529e-05 
0 
0.000128772 
1.26589e-05 
0 
0 
5.5792e-05 
1.28968e-05 
1.62265e-05 
0.000129914 
0 
0 
1.40766e-05 
0 
0 
0 
5.70435e-05 
0 
0 
0 
1.43713e-05 
1.44177e-05 
1.32216e-05 
0.000140718 
1.52296e-05 
5.7204e-05 
1.52818e-05 
1.9234e-05 
5.68687e-05 
1.45115e-05 
0 
5.48847e-05 
1.34204e-05 
1.34204e-05 
1.31437e-05 
0 
0 
1.2695e-05 
1.28968e-05 
0 
0 
1.3667e-05 
1.3667e-05 
5.77933e-05 
1.3667e-05 
1.588e-05 
0 
0 
0.000143733 
1.56846e-05 
1.36253e-05 
0 
5.42956e-05 
0 
0 
5.64526e-05 
0.000218408 
0 
0 
0 
5.38065e-05 
6.46013e-05 
1.30667e-05 
6.21716e-05 
0 
0.000236459 
1.28226e-05 
1.45588e-05 
0 
1.71957e-05 
1.31631e-05 
1.62857e-05 
1.56846e-05 
0 
5.71172e-05 
5.5432e-05 
0.000130578 
6.09208e-05 
1.47758e-05 
1.48003e-05 
0 
0 
0 
5.88011e-05 
0 
1.28596e-05 
1.35426e-05 
1.30476e-05 
5.0683e-05 
1.32412e-05 
0 
0 
5.28445e-05 
1.43713e-05 
2.24235e-05 
1.95286e-05 
1.95286e-05 
6.44373e-05 
5.64831e-05 
1.37301e-05 
# Learning phase...
 - Before training
Accuracy: 202/243 = 0.831276
Average error toward 0: -0.000504367 (20)
Average error toward 1: 0.000633759 (21)
Prev: 0.460905 (error: 0.0823045) Offset: 0 0
Ratio error 1 : 0.512195
-----------------
- 111 - 21 - 
-----------------
- 20 - 91 - 
-----------------
 - Phase 1
Accuracy: 204/243 = 0.839506
Average error toward 0: -0.000896 (20)
Average error toward 1: 0.001139 (19)
Prev: 0.460905 (error: 0.082305) Offset: 0.000000 0.000000
Ratio error 1 : 0.487179
-----------------
- 111 - 19 - 
-----------------
- 20 - 93 - 
-----------------
 - Verification
Accuracy: 214/243 = 0.880658
Average error toward 0: -0.001012 (11)
Average error toward 1: 0.001464 (18)
Prev: 0.460905 (error: 0.045267) Offset: 0.000000 0.000000
Ratio error 1 : 0.620690
-----------------
- 120 - 18 - 
-----------------
- 11 - 94 - 
-----------------
Serialization of post-training strength vectors...
# Predictions
# Already in case-base: 0 -nan
0.609824
Accuracy: 21/26 = 0.807692
Average error toward 0: -0.000023 (4)
Average error toward 1: 0.000027 (1)
Prev: 0.460905 (error: 0.016461) Offset: 0.000000 0.000000
Ratio error 1 : 0.200000
-----------------
- 14 - 1 - 
-----------------
- 4 - 7 - 
-----------------
# Prediction serialization...
# Saving the [26,347] weight matrix...
0.060174
