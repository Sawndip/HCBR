# Loading the instance files...
# Perform sanity checks on the dataset
# Setting the parameters...
# Initialize...
# Online: 1
# Verbose level: 0
# Cases: 245057
# Total features: 735171
# Unique features: 768 (ratio: 0.00104465)
# Minimum case size: 3
# Maximum case size: 3
# Average case size: 3
# Add cases...
# Model serialization...
# Saving the [220551,768] weight matrix...
# Calculate intrinsic strength...
Calculate strength for 220551
Serialization of pre-training strength vectors...
0.00347103 
0.000912383 
0.00428691 
0.000416774 
0.000434145 
0.000447337 
0.00170608 
0.00147014 
0.00283503 
0.00773864 
0.00173624 
0.0028393 
0.000157597 
0.00185708 
0.00146323 
0.00115528 
0.00357644 
0.00286725 
0.00056153 
0.0017869 
0.000944911 
0.00446319 
0.000810623 
0.000120837 
0.0068614 
0.00129195 
0.000311675 
0.00230984 
0.000674237 
0.00106067 
0.00106446 
0.00343098 
0.000907013 
0.000881497 
0.000199118 
0.00269943 
9.34237e-05 
0.00107827 
0.00675706 
0.00506792 
0.00487385 
0.00394054 
0.0252364 
0.000531653 
0.00713429 
0.000676726 
0.00062792 
7.43418e-05 
0.00215232 
0.00200721 
0.000898376 
0.00152519 
0.000867101 
0.000748756 
0.0063077 
0.000135266 
0.00304511 
0.000133615 
0.00441328 
0.00123155 
0.000521481 
0.00596105 
0.00137139 
4.32924e-05 
0.000855772 
0.00031605 
0.000496129 
0.000574542 
0.00663456 
0.000878383 
0.000161256 
0.000554731 
0.00423134 
0.00609132 
0.000873292 
0.00161826 
0.000246392 
0.00935469 
0.00636563 
0.00152712 
0.000871127 
0.00124426 
0.000465234 
0.00160638 
6.64873e-05 
0.000139502 
0.00106666 
0.00592357 
0.000346401 
0.000488013 
0.00247948 
0.00127523 
0.00353347 
0.00134171 
0.000338804 
0.00510825 
0.00691659 
0.00301647 
0.00423735 
0.00123646 
0.00344932 
0.0091526 
0.00022394 
0.00055006 
0.000856159 
0.000693338 
0.00102123 
0.00811692 
0.0012928 
0.000391089 
0.00227557 
0.000334282 
0.00169361 
0.00508445 
0.00241497 
0.000398517 
0.00109789 
3.27679e-05 
0.000601996 
0.00214198 
0.000582862 
0.00102214 
0.00120347 
0.00262928 
0.00225824 
0.000276054 
0.00271755 
0.00149933 
0.00093347 
0.00275698 
0.000873734 
0.0035783 
0.000138047 
0.000906397 
0.00455417 
0.000752668 
0.00263527 
0.000667541 
0.00725235 
0.00150113 
0.000576477 
0.000609855 
0.00138101 
0.00144233 
0.00017328 
0.00047427 
0.000727454 
0.000854659 
0.00141996 
0.0043982 
0.00358925 
0.0034299 
0.00546989 
0.00764677 
0.000816291 
0.000743852 
6.72626e-05 
0.00102571 
0.00425277 
0.00133198 
0.000834181 
0.00127985 
0.00404009 
0.00106791 
0.000872317 
0.00064326 
0.000181882 
0.00435308 
0.00241509 
0.000516145 
0.000400905 
0.000728921 
0.000356969 
0.000898409 
9.61575e-05 
3.76799e-05 
0.00629664 
0.00754231 
0.00406307 
0.00105282 
0.00831392 
0.00981763 
0.000840309 
0.00114418 
0.00350303 
0.00112555 
0.000607952 
0.00339515 
0.00287405 
0.000867047 
0.000717046 
0.000537893 
0.00310233 
0.00125921 
0.0056348 
0.00680481 
0.000990141 
0.000631443 
0.00011301 
0.000676395 
0.00058443 
0.000613605 
0.000518368 
0.00146383 
0.00601726 
0.00388811 
0.00592564 
5.94705e-05 
0.000162447 
0.00319188 
0.0022249 
0.000980294 
0.00220359 
0.000487719 
0.00184656 
0.00151201 
0.000624737 
0.000438944 
0.00126422 
0.00167942 
0.00405698 
0.000915112 
0.00193151 
0.00493729 
0.00170427 
0.00378238 
0.00343753 
0.00113615 
0.00156839 
0.00137782 
0.000598368 
0.00143402 
0.00178697 
0.00478576 
0.00265388 
0.00445004 
0.00791875 
0.00709867 
0.00669425 
0.00104677 
0.00133562 
7.24448e-05 
0.000469635 
0.00081982 
0.000508297 
0.00658737 
0.000397597 
0.00136693 
0.00380852 
0.00405325 
0.00130441 
0.00176338 
0.000540766 
0.00051591 
0.00192861 
0.00163796 
0.00182059 
7.4298e-05 
0.00183635 
0.000757924 
0.00352987 
0.000370933 
0.00132094 
0.000433805 
0.00202104 
0.000600795 
0.000650813 
0.00176254 
0.00051847 
0.000380854 
0.000711609 
0.00217459 
0.00505476 
0.00230255 
0.00113056 
0.00066561 
0.00144348 
0.00134178 
0.000890988 
0.000868887 
0.00514737 
0.00376561 
0.00108519 
5.3824e-05 
0.0011244 
0.00431836 
0.00303913 
0.00455077 
0.00511229 
0.00106691 
0.000302713 
0.00017031 
0.00104001 
0.00194559 
0.000973622 
0.000318178 
0.00155809 
0.000401801 
0.00139246 
0.00399985 
0.000681689 
0.000167345 
0.00156391 
0.00116511 
0.00156663 
0.000605612 
0.00161992 
0.000962791 
2.49884e-05 
0.000434622 
0.000360815 
0.000859386 
0.00106731 
0.000462768 
0.0001331 
0.00151387 
0.00218269 
0.000825554 
0.000273726 
0.000501919 
0.00281427 
0.000184526 
0.000991664 
0.00152029 
0.00021355 
0.000591252 
0.000822354 
8.71989e-05 
0.0016245 
0.000625597 
0.000621148 
0.000520288 
0.000579556 
0.00120266 
0.000987156 
0.00124177 
0.000158737 
0.0010255 
0.00188759 
0.00059082 
0.000118701 
0.00017771 
0.00147339 
0.000464755 
0.00172562 
0.00111788 
0.00522693 
0.000801192 
0.00127495 
0.000459328 
5.05877e-05 
0.00176083 
0.000846919 
0.000540872 
0.000190001 
0.00115133 
0.00130592 
0.00349811 
0.00105103 
0.0015532 
0.00146164 
0.00096509 
0.000939379 
0.00107282 
0.000538114 
0.00171368 
0.00178527 
0.00245889 
0.00394202 
0.00414251 
0.00415018 
0.000393845 
0.000462496 
2.94191e-05 
0.0041243 
0.00136307 
0.000100097 
0.0024238 
0.00126275 
0.00129676 
0.00395194 
0.00053488 
0.000348711 
0.000952098 
0.000352118 
0.00175569 
0.00149866 
0.00169299 
0.00068481 
0.00124337 
0.0010162 
0.000430333 
0.000118414 
0.000364495 
0.000732199 
0.000566288 
0.00076248 
0.000708534 
0.000739827 
0.000734268 
0.00220052 
0.00072749 
0.00147836 
0.00280507 
0.000504824 
0.00145642 
0.000402186 
0.00121046 
0.000447495 
0.000528412 
0.000466333 
0.000212909 
0.00114062 
0.000913839 
0.000588049 
0.000476832 
0.000602791 
0.000814876 
0.000774295 
0.000680976 
0.00177405 
0.000473065 
0.00111839 
0.0019748 
0.00194405 
0.000175185 
0.00224798 
0.00330543 
0.000456939 
0.000270738 
0.000376977 
0.00190072 
0.000937097 
0.000564603 
0.000464599 
0.000672589 
0.00138439 
0.000625894 
0.001336 
0.00137227 
0.000463838 
0.000158036 
0.000230537 
5.4902e-05 
0.000198249 
0.000850671 
0.00030084 
0.00170634 
0.000765933 
0.000127216 
0.00132821 
0.000213452 
0.000242668 
0.00051419 
0.00169386 
0.00187244 
0.000664529 
0.00131203 
0.000550085 
0.000328757 
0.00105964 
0.00204568 
0.000823306 
0.000182595 
0.00096982 
0.00110971 
0.00130661 
0.000121761 
0.000182033 
0.00058627 
0.000412357 
0.000231829 
6.37862e-05 
0.00244121 
0.00284195 
0.00184524 
0.000741636 
0.00131746 
0.000644535 
0.0006177 
0.0018436 
0.000208979 
0.00276418 
0.000460836 
0.000506303 
0.00135388 
0.00117505 
0.000533489 
0.000442455 
0.000752569 
0.000461168 
0.000248988 
0.000512216 
0.000847774 
0.000413497 
0.000182876 
0.000489205 
0.000379395 
0.00235475 
0.00034487 
0.00287503 
0.00105103 
0.000646751 
0.00138582 
0.000171096 
0.000441582 
0.000272015 
0.000655273 
3.20667e-05 
0.000461487 
0.000199185 
0.000150571 
0.00158635 
0.000477611 
0.00259861 
0.000165158 
0.000249972 
0.000841948 
0.00149264 
0.000830974 
9.41457e-05 
0.00253949 
0.00113622 
0.000201427 
0.00157855 
0.000471391 
0.000603304 
0.000777991 
0.00100978 
0.000122806 
0.000957266 
0.000438915 
0.0005999 
0.000475221 
0.000170752 
0.000898431 
0.000691666 
0.000156879 
0.00138581 
0.00234757 
0.000329105 
0.000608362 
0.000679815 
0.00130106 
0.00122921 
0.000362763 
0.000234809 
0.00151256 
0.00108872 
0.000260207 
0.000657465 
0.000223979 
0.000562262 
0.00106428 
0.000789178 
6.04772e-05 
0.000423648 
0.000503088 
0.0013506 
4.39657e-05 
2.85324e-05 
0.000551151 
0.00103923 
0.000803713 
0.000181013 
9.83081e-05 
0.000787493 
0.000730719 
0.000943555 
0.00089239 
0.000693737 
0.00244433 
0.000133042 
0.000592267 
0.000472094 
0.000122254 
0.0014904 
0.00109378 
0.00208339 
0.00116276 
0.00250812 
0.000193037 
0.000844803 
0.000791111 
4.49329e-05 
0.000868275 
0.00149872 
0.000527459 
0.000808055 
0.000492624 
0.000447555 
3.51728e-05 
0.000756791 
0.000418238 
0.00109872 
0.000725642 
0.00107618 
0.000708189 
0.000835264 
0.000496219 
0.000498029 
0.000733004 
0.000739035 
0.000308881 
0.000154169 
0.000162972 
0.000235195 
0.00017959 
8.98552e-05 
0.000650217 
0.000710321 
0.00113234 
8.14764e-05 
0.000634762 
0.00155614 
0.000958196 
0.00158043 
0.000141112 
0.000953933 
0.000423379 
0.000176478 
7.26e-05 
0.000812175 
0.00101783 
0.000490761 
0.000476701 
0.000199309 
0.000290032 
0.00039499 
0.00200751 
0.000107885 
0.00116866 
0.000233084 
0.000252563 
8.68079e-05 
4.08147e-05 
0.000867907 
0.000515572 
8.51938e-05 
0.00038929 
0.000123316 
0.000800564 
0.000648188 
0.00056418 
0.00023658 
0.000126145 
0.000382972 
0.000140099 
0.000830847 
0.000630837 
0.000651281 
0.000318991 
0.000343128 
6.63352e-05 
0.000773089 
0.00308414 
0.000537665 
0.000468558 
0.000429069 
0.000387554 
0.000478815 
0.000712788 
0.000156153 
0.00139701 
0.000194283 
0.000291892 
0.000701657 
0.000606094 
0.00029538 
0.000526644 
0.00042593 
0.00155508 
4.6693e-05 
6.83428e-05 
0.000611938 
0.00018349 
0.000307487 
0.000618136 
0.000296896 
0.000581338 
0.000466072 
0.00155787 
3.88354e-05 
0.000363874 
0.000421448 
0.000833035 
0.000395761 
0.000271614 
0.0011558 
0.000164118 
0.000797566 
0.000689234 
0.000264788 
7.94278e-05 
4.81048e-05 
0.00017777 
0.000159 
0.000188911 
8.88825e-05 
0.00023912 
2.90464e-05 
8.25346e-05 
0.000318078 
0.000227386 
0.000361198 
3.31768e-05 
0.00018579 
0.000527093 
0.000160493 
0.000107138 
0.000105281 
0.000463993 
0.000541255 
0.00052611 
7.46297e-05 
0.000883078 
0.000767766 
0.000157751 
4.24915e-05 
0.000106645 
0.000178327 
0.000698745 
0.000198533 
2.96433e-05 
4.84532e-05 
0.00012295 
2.7226e-05 
3.41686e-05 
0.00023124 
3.84521e-05 
0.000124433 
4.2349e-05 
0.000747097 
0.000118661 
0.000183392 
0.000213931 
0.000124431 
0.000192172 
0.000184514 
3.42915e-05 
0.00028547 
2.95462e-05 
0.000418323 
0.000177636 
0.000105759 
0.000171471 
0.000133795 
0.000379655 
0.000255771 
0.000221134 
0.000127243 
0.000278227 
0.000281787 
8.90251e-05 
0.000285889 
2.75754e-05 
0.000164744 
2.57648e-05 
0.000107166 
0.000246589 
0.000235148 
3.404e-05 
0.000201642 
2.43484e-05 
3.90053e-05 
4.67439e-05 
3.74565e-05 
0.000105434 
# Learning phase...
 - Before training
Accuracy: 174416/220551 = 0.790819
Average error toward 0: -1.47265e-05 (4103)
Average error toward 1: 0.000245165 (42032)
Prev: 0.792588 (error: 0.0186034) Offset: 0 0
Ratio error 1 : 0.911065
-----------------
- 41642 - 42032 - 
-----------------
- 4103 - 132774 - 
-----------------
 - Phase 1
Accuracy: 211038/220551 = 0.956867
Average error toward 0: -0.000015 (4197)
Average error toward 1: 0.000246 (5316)
Prev: 0.792588 (error: 0.019030) Offset: 0.000000 0.000000
Ratio error 1 : 0.558814
-----------------
- 41548 - 5316 - 
-----------------
- 4197 - 169490 - 
-----------------
 - Verification
Accuracy: 211256/220551 = 0.957856
Average error toward 0: -0.000015 (5087)
Average error toward 1: 0.000246 (4208)
Prev: 0.792588 (error: 0.023065) Offset: 0.000000 0.000000
Ratio error 1 : 0.452717
-----------------
- 40658 - 4208 - 
-----------------
- 5087 - 170598 - 
-----------------
Serialization of post-training strength vectors...
# Predictions
# Already in case-base: 21236 0.999812
0.952554
Accuracy: 24117/24505 = 0.984166
Average error toward 0: -0.000000 (136)
Average error toward 1: 0.000000 (252)
Prev: 0.792588 (error: 0.000617) Offset: 0.000000 0.000000
Ratio error 1 : 0.649485
-----------------
- 4978 - 252 - 
-----------------
- 136 - 19139 - 
-----------------
# Prediction serialization...
# Saving the [24505,768] weight matrix...
56.772106
