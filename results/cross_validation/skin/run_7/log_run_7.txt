# Loading the instance files...
# Perform sanity checks on the dataset
# Setting the parameters...
# Initialize...
# Online: 1
# Verbose level: 0
# Cases: 245057
# Total features: 735171
# Unique features: 768 (ratio: 0.00104465)
# Minimum case size: 3
# Maximum case size: 3
# Average case size: 3
# Add cases...
# Model serialization...
# Saving the [220551,768] weight matrix...
# Calculate intrinsic strength...
Calculate strength for 220551
Serialization of pre-training strength vectors...
0.000505825 
0.000548656 
0.000175413 
4.59244e-05 
0.0011736 
0.00391117 
0.000155385 
0.000102089 
0.000556057 
0.00183587 
0.000742639 
0.0017736 
0.00354468 
0.000227833 
0.00599431 
0.0253099 
0.000524277 
0.00601849 
0.000170237 
0.00105666 
0.00100563 
0.00180701 
0.000593151 
0.00106739 
0.00339486 
0.00136211 
0.00107945 
0.000777802 
0.00504773 
3.46046e-05 
0.0025565 
0.000474053 
0.00663315 
0.00273555 
0.00128501 
0.0024397 
0.000731661 
0.000411686 
0.000807983 
0.00110954 
0.00155425 
0.000915313 
0.000870507 
0.00598347 
0.00145024 
0.000406704 
0.00413409 
0.00076458 
0.000520509 
0.000576044 
0.00048255 
0.000294812 
0.00110732 
0.00206521 
0.00169584 
0.000354982 
0.00333363 
0.0036274 
0.00264767 
0.00109445 
0.00206146 
0.00129089 
0.0039759 
0.00356649 
0.00431026 
0.00132409 
0.00350058 
0.00119784 
0.00169933 
0.000196586 
0.000517675 
9.56214e-05 
0.0030857 
0.00115591 
0.000567695 
0.000794313 
0.000433669 
0.00294775 
0.000682981 
0.00012002 
0.00120431 
0.00103457 
0.00634043 
0.00973523 
0.00756327 
0.00717904 
0.00154159 
0.00144791 
0.00137321 
0.000875369 
0.000603724 
0.000423427 
0.00120615 
0.00043617 
0.000961595 
0.000150312 
0.000860995 
0.000947607 
0.00608076 
0.00688674 
0.00498516 
0.00314201 
0.00400726 
0.00277493 
0.00482235 
0.00105101 
0.00157995 
0.000347074 
0.000685465 
0.000655554 
0.000209305 
0.000506962 
0.00101199 
0.00674488 
0.00776829 
0.00635378 
0.00148499 
0.000499191 
0.00120885 
0.00123611 
0.000526472 
0.00261743 
0.00273273 
0.000610418 
0.000586229 
0.000412417 
0.0011311 
0.000871684 
0.00175842 
0.00211533 
0.00669924 
0.00777859 
0.000851925 
0.00921135 
0.00503367 
0.00350802 
0.00118235 
0.00102278 
0.00029423 
0.00171492 
0.000776989 
0.000149459 
0.000195696 
0.00453772 
0.000892837 
0.000562571 
0.00169013 
0.00132642 
0.000423834 
0.00450519 
0.00384055 
0.00140608 
0.00160878 
0.00256068 
0.000985549 
0.000197426 
0.00145219 
0.000288867 
0.000443447 
0.000422027 
0.00191418 
0.00170872 
0.00222529 
0.000446202 
0.000912951 
0.00149051 
0.000584212 
0.000181862 
0.00302751 
0.00124146 
0.00105663 
0.00107445 
0.000585591 
0.0040087 
0.000546268 
0.00501329 
0.00145658 
0.002833 
0.000117546 
0.00134252 
0.00159264 
0.000962029 
0.000532546 
0.00130637 
0.00077995 
0.00123286 
0.00152957 
0.000187394 
0.00130146 
0.00162978 
0.000701792 
0.00137206 
0.000875372 
0.000567949 
0.0046395 
0.00641461 
0.00136083 
0.0013491 
0.00135674 
0.000491206 
0.000827872 
0.0045163 
0.000364681 
0.000281018 
0.000850991 
0.00298783 
0.00684491 
0.000277109 
0.0002094 
0.000787221 
0.00265541 
0.000664032 
0.00234827 
0.00146195 
0.00173445 
0.00354686 
0.00403493 
0.00511455 
0.00777972 
0.00423462 
0.000338587 
0.00134813 
0.00133866 
0.00284894 
0.000438085 
0.00109597 
0.00104936 
4.15301e-05 
0.00115064 
0.000149338 
0.00113445 
0.0015883 
0.00421322 
0.00110844 
0.00607118 
0.00215662 
0.000623551 
0.00923962 
0.00248491 
0.000132335 
0.00100666 
0.000296088 
0.00296372 
0.00083899 
0.000804095 
0.000516333 
0.000924051 
0.00407747 
0.00140818 
0.000962384 
4.07195e-05 
0.00156689 
0.00178795 
0.000902645 
0.00013715 
0.000477323 
0.000432473 
0.000733774 
0.00165577 
0.000764727 
0.00245062 
0.000419327 
0.000834626 
0.000478441 
0.00447573 
0.000177517 
0.000421382 
0.00114429 
0.00423107 
0.00113446 
0.000912742 
0.000157811 
0.000848193 
0.00365894 
0.0014879 
0.000564412 
0.0023669 
0.000755998 
0.000168 
0.000740367 
0.000169561 
0.00149742 
0.000915698 
0.000455379 
0.000394139 
0.000518393 
0.000402931 
0.000240291 
0.000853873 
0.000173006 
0.00427047 
0.00481974 
0.000351119 
0.00132769 
0.00136893 
0.00084036 
0.00427658 
0.00123789 
0.00358935 
0.00152603 
0.00220331 
0.00227684 
0.000993644 
0.00251895 
0.000178167 
0.00128676 
0.00124573 
0.00197904 
0.000748301 
0.00143995 
0.000409948 
0.000236749 
0.00557881 
0.00214617 
0.00110158 
0.00816393 
0.000219964 
0.000165756 
0.0038044 
6.06883e-05 
0.000381759 
0.000319777 
0.00102852 
0.00192638 
0.00135142 
0.00386143 
0.00237438 
0.00329389 
0.000481955 
0.00145616 
0.000462269 
0.0003708 
0.000917215 
0.00168986 
0.00272191 
0.000715991 
0.00048238 
0.000117323 
0.00199355 
0.00104274 
0.000659353 
0.00233979 
0.00409186 
0.00800697 
0.00405433 
0.000449204 
0.000548187 
0.00141582 
0.00115558 
0.000559044 
0.000267448 
0.000854439 
0.000364247 
0.000493008 
0.00119783 
0.000578981 
0.00164919 
0.00155115 
0.000568809 
0.00708349 
0.00497789 
0.000314823 
0.00219606 
0.0018583 
0.000381144 
0.00704887 
0.00185826 
0.000761193 
0.00113198 
0.000344966 
0.00244354 
0.000613447 
0.000886935 
6.16286e-05 
0.00081732 
0.00144218 
0.00132678 
0.00106801 
0.000161781 
0.00214954 
0.00101848 
0.00033432 
0.000555203 
0.00123969 
0.000745703 
0.0015612 
0.000201719 
0.000756121 
0.00111318 
0.000652329 
0.000132927 
3.63877e-05 
0.00024502 
0.00107035 
0.000661702 
0.00114564 
0.00136541 
0.000111981 
7.43068e-05 
0.000753074 
0.00086783 
0.000348144 
0.00083181 
0.000750928 
0.00135092 
0.000890919 
0.000719582 
0.000166836 
0.00110613 
0.000456922 
0.000689674 
0.00133759 
0.000869928 
0.00104604 
0.000920572 
0.000784524 
0.00178949 
0.00169325 
0.000160916 
0.000510021 
0.00190833 
0.00176038 
0.00147836 
0.000565678 
0.000278568 
0.000513061 
0.000445179 
0.00204698 
0.00187131 
0.00236189 
0.00506529 
0.00517286 
0.00134443 
0.00174479 
0.001282 
0.000670149 
0.000432642 
0.000113949 
2.62925e-05 
0.000491711 
0.00147304 
0.000179502 
0.0024581 
0.000564847 
0.000870481 
0.000197195 
0.000744087 
0.000922598 
0.000635788 
0.00070416 
0.0020685 
0.00137718 
0.000668108 
0.000730024 
0.00330616 
0.00084453 
0.000609709 
0.00080913 
6.15776e-05 
0.00104227 
0.000574974 
0.000848386 
0.00174292 
3.55366e-05 
0.000748615 
0.000990139 
0.00200541 
0.000601149 
0.000853236 
0.000676246 
0.000619428 
0.000658486 
0.000499949 
0.000669032 
0.00149085 
0.00275137 
0.00448815 
0.000510803 
0.00163685 
0.00060333 
0.0054632 
0.00392843 
0.000318626 
0.000940563 
0.000511687 
0.00133187 
0.000177633 
0.00192104 
0.00665335 
0.00342807 
0.00132323 
0.000939878 
7.22851e-05 
0.000886056 
0.00023939 
6.4987e-05 
0.000660131 
0.000543422 
0.000644865 
0.00152532 
0.000126471 
0.000833043 
0.00207176 
0.000478666 
0.000649301 
0.000922807 
0.0010609 
0.00242284 
0.000994664 
0.00150991 
0.000162902 
0.000409461 
0.000839883 
0.00381569 
0.000933073 
0.0010558 
0.000439831 
8.46515e-05 
0.000565545 
0.000224128 
0.000593113 
0.00158359 
0.00338784 
0.00162167 
0.000475856 
0.00219287 
0.00166799 
0.00410769 
0.00079828 
0.000319205 
0.000793428 
9.73809e-05 
0.000202304 
0.000995045 
0.000329917 
0.000706355 
0.000655413 
0.000138419 
0.000133744 
0.00162143 
0.00133735 
0.00288888 
0.000825923 
0.0066658 
0.000378653 
0.00267778 
0.00030273 
0.0014579 
0.000215273 
0.000332346 
0.000640644 
0.000232815 
4.20614e-05 
0.000375509 
0.000183767 
8.13685e-05 
0.000476417 
0.000450123 
0.000864758 
0.000207448 
0.000211296 
8.47128e-05 
0.000791388 
0.000376859 
0.00210898 
0.000138124 
0.000668004 
7.27415e-05 
0.000256819 
0.000584498 
0.000503129 
0.00044479 
0.000527929 
0.00150191 
0.000638457 
0.00286123 
0.000761474 
0.00115151 
0.000491144 
0.000245486 
0.000128548 
0.000784443 
0.000190692 
0.000690209 
3.10548e-05 
0.000535797 
0.000175056 
0.00094253 
0.000226719 
0.000325678 
0.00134082 
0.000633826 
0.000824743 
0.000842126 
0.000682884 
0.000322264 
0.000747828 
2.87025e-05 
0.000151242 
0.000852261 
8.01262e-05 
0.000442314 
0.000668348 
0.000740899 
0.00356127 
0.000460362 
0.000441572 
0.000638672 
0.000231526 
0.000569501 
0.000576625 
0.000126664 
3.74002e-05 
0.00120381 
0.000405717 
0.00017049 
0.000511368 
0.000185795 
0.000231345 
0.000659269 
0.000222672 
0.000793503 
0.000549887 
0.00041731 
0.000189345 
0.00121153 
0.00105216 
0.00082059 
0.000390619 
0.000218426 
0.000419394 
0.000693206 
0.00212347 
3.08232e-05 
0.000446966 
0.000269635 
0.000357176 
0.000617081 
0.000894709 
7.36948e-05 
0.000100943 
0.000477911 
0.000207616 
0.000738695 
0.000196008 
0.000407132 
0.000832272 
0.00104054 
0.000318265 
0.000502296 
2.96931e-05 
0.000694582 
0.000595484 
0.000472182 
0.000495506 
0.000868169 
0.000506559 
0.00052922 
0.000491058 
0.00283033 
0.000257131 
0.000156358 
0.00105577 
0.000672478 
0.000689333 
0.000788911 
0.000645293 
0.000682017 
0.000731224 
0.00181098 
0.000111679 
0.0017984 
0.000242188 
0.000917176 
0.000484939 
0.000504005 
0.000210117 
0.000190582 
0.000129024 
0.00105422 
0.000413534 
8.08876e-05 
4.70618e-05 
0.000483506 
0.000131831 
0.000560227 
0.000875514 
0.000618771 
0.00158369 
0.000174294 
0.00016493 
6.31233e-05 
0.000128502 
0.000143849 
0.00042218 
0.000282413 
0.000624831 
0.000133414 
0.00029217 
0.000116711 
0.000156151 
6.98515e-05 
0.000191925 
0.00132119 
0.000315486 
0.000222905 
0.000115836 
3.24036e-05 
7.52481e-05 
0.000131366 
0.000154019 
0.00021081 
0.000564413 
0.00046451 
0.000109119 
8.8397e-05 
0.000223089 
0.000268944 
0.000211777 
0.000390057 
0.000403687 
0.000341193 
0.000274085 
0.000301533 
0.000103962 
0.000249111 
8.99321e-05 
7.89691e-05 
9.93975e-05 
6.07397e-05 
2.32777e-05 
4.02048e-05 
0.000122431 
5.9146e-05 
0.000484767 
4.15804e-05 
8.34968e-05 
0.000121596 
0.000159879 
0.0001381 
0.000255451 
5.10345e-05 
5.71634e-05 
0.000262106 
5.3903e-05 
0.000647062 
4.67919e-05 
9.41925e-05 
0.000129345 
0.00028767 
0.000204818 
2.85182e-05 
2.91744e-05 
0.000167091 
0.000299 
4.73184e-05 
2.80877e-05 
4.49006e-05 
3.91626e-05 
3.21869e-05 
0.00019277 
4.79199e-05 
2.60582e-05 
0.000119219 
3.02547e-05 
4.54836e-05 
9.69554e-05 
2.72459e-05 
# Learning phase...
 - Before training
Accuracy: 174314/220551 = 0.790357
Average error toward 0: -1.4601e-05 (4115)
Average error toward 1: 0.000247001 (42122)
Prev: 0.792406 (error: 0.0186578) Offset: 0 0
Ratio error 1 : 0.911002
-----------------
- 41670 - 42122 - 
-----------------
- 4115 - 132644 - 
-----------------
 - Phase 1
Accuracy: 210993/220551 = 0.956663
Average error toward 0: -0.000015 (4264)
Average error toward 1: 0.000248 (5294)
Prev: 0.792406 (error: 0.019333) Offset: 0.000000 0.000000
Ratio error 1 : 0.553882
-----------------
- 41521 - 5294 - 
-----------------
- 4264 - 169472 - 
-----------------
 - Verification
Accuracy: 211255/220551 = 0.957851
Average error toward 0: -0.000015 (4964)
Average error toward 1: 0.000248 (4332)
Prev: 0.792406 (error: 0.022507) Offset: 0.000000 0.000000
Ratio error 1 : 0.466007
-----------------
- 40821 - 4332 - 
-----------------
- 4964 - 170434 - 
-----------------
Serialization of post-training strength vectors...
# Predictions
# Already in case-base: 21201 0.999906
0.956438
Accuracy: 24150/24505 = 0.985513
Average error toward 0: -0.000000 (110)
Average error toward 1: 0.000000 (245)
Prev: 0.792406 (error: 0.000499) Offset: 0.000000 0.000000
Ratio error 1 : 0.690141
-----------------
- 4963 - 245 - 
-----------------
- 110 - 19187 - 
-----------------
# Prediction serialization...
# Saving the [24505,768] weight matrix...
53.871797
