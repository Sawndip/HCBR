# Loading the instance files...
# Perform sanity checks on the dataset
# Setting the parameters...
# Initialize...
# Online: 1
# Verbose level: 0
# Cases: 245057
# Total features: 735171
# Unique features: 768 (ratio: 0.00104465)
# Minimum case size: 3
# Maximum case size: 3
# Average case size: 3
# Add cases...
# Model serialization...
# Saving the [220551,768] weight matrix...
# Calculate intrinsic strength...
Calculate strength for 220551
Serialization of pre-training strength vectors...
0.00166285 
0.00279971 
0.00199287 
0.0251648 
0.000490326 
0.000829774 
0.000520159 
0.00135459 
0.000151678 
0.00695052 
4.7504e-05 
0.00695132 
0.00185097 
0.000222449 
0.00508228 
0.00788364 
3.64009e-05 
0.00371761 
0.00679425 
0.00155228 
0.00151381 
0.000579961 
0.00245413 
0.000777887 
0.00248365 
0.00357404 
0.000859811 
0.000818373 
0.00283543 
0.0034509 
0.00284122 
0.0020392 
0.00306071 
0.00404684 
0.00376667 
0.000774405 
0.000423807 
0.000427832 
0.00403515 
0.00121214 
0.00288237 
0.00663803 
0.00657937 
0.000297764 
0.0019533 
0.000590103 
0.002817 
0.00151978 
0.000153221 
0.000152548 
0.00182353 
0.00406426 
0.000289128 
0.00311021 
0.00635958 
0.00937299 
0.000722168 
0.00206515 
0.00611102 
0.000408116 
0.00112211 
0.0002385 
0.000495186 
0.00244234 
0.00105647 
0.0018065 
0.00821433 
0.0001654 
0.00423366 
0.000568347 
0.00114881 
0.00488065 
0.00149446 
0.000907112 
0.00510282 
0.0042582 
0.00110244 
0.000788404 
0.00736244 
0.00785436 
0.00669917 
0.000554023 
0.000434148 
0.000583564 
0.00410544 
0.000655121 
0.000870479 
0.000558904 
6.90728e-05 
0.00223521 
0.00357423 
0.00222558 
0.00190041 
0.000606527 
0.00145474 
0.00105859 
0.000281228 
0.00556009 
0.00171482 
0.00140518 
0.000714767 
0.00780049 
0.00629431 
0.000397449 
0.000494882 
0.000727863 
0.000814346 
0.00184273 
0.000187052 
0.00131134 
0.000984237 
0.00448346 
0.00588306 
0.00465058 
0.000138793 
0.00075571 
0.000676747 
0.00121855 
0.00604636 
0.00425728 
0.000893113 
0.000635069 
0.00110739 
0.000154661 
0.00916137 
0.000482446 
0.00215892 
0.000939851 
0.000166191 
0.000426912 
0.00215823 
0.00336115 
0.000932694 
0.000166433 
0.00481271 
0.0015072 
0.00452016 
0.00629536 
0.0014276 
0.00344584 
0.000375661 
0.00156227 
0.00192846 
0.000999758 
0.000786071 
0.00102188 
0.000874095 
0.00491876 
0.000148357 
0.00138002 
0.000824179 
0.000682476 
0.0014507 
0.000864206 
0.000585122 
0.000180275 
0.000197953 
0.00153949 
0.00137357 
0.00677792 
0.00247437 
0.00167536 
0.00418718 
0.00174346 
0.000493263 
0.00503434 
0.00421528 
0.00105718 
0.00115515 
0.000898544 
0.00109203 
0.000223141 
0.00710005 
0.000436101 
0.000828115 
0.00110603 
0.000772073 
0.00155487 
0.000472678 
0.000339588 
0.000727124 
0.0054472 
0.00107215 
0.00269552 
0.00114465 
0.000562665 
0.00108136 
0.00342552 
0.000175701 
0.000846444 
0.0021373 
0.000417533 
0.000176976 
0.00422599 
0.00133087 
0.00139672 
0.000419774 
0.000968088 
0.00742152 
0.000267618 
0.00376626 
0.00486256 
0.00352629 
0.00146289 
0.00220604 
0.00127396 
0.00105552 
0.000567873 
0.000912951 
0.0012427 
0.00044419 
0.000485861 
0.00100901 
0.0080738 
0.00230704 
0.00389422 
0.00368759 
6.33891e-05 
0.00180922 
0.000235278 
0.001097 
0.00160041 
0.00344842 
0.00137277 
0.00440284 
0.00144224 
0.00397972 
0.000603877 
0.000932081 
0.00088145 
0.00163605 
0.0039403 
0.000447398 
0.000540775 
0.00330152 
0.00302345 
0.000353925 
0.00103525 
0.000357777 
0.00119553 
0.00384468 
0.00593884 
0.00267786 
0.00124665 
0.000190114 
0.000545135 
0.000286891 
0.000854833 
0.00151284 
0.00148937 
0.000565654 
0.0013286 
6.28331e-05 
0.00177839 
0.00104796 
0.00218706 
0.000503025 
0.000564451 
0.00141045 
0.000475404 
0.0018959 
0.000215234 
0.000483227 
0.000727847 
0.000763285 
0.000553426 
0.00350995 
0.00110041 
0.00233319 
0.000775645 
0.00133407 
0.00288275 
0.000337591 
0.00115488 
0.00136941 
0.00137143 
0.00111158 
0.000150701 
0.000183271 
0.00102085 
0.00164735 
0.00107997 
0.00167353 
0.00126852 
0.00444036 
0.000771627 
0.000686892 
0.000401074 
0.0006234 
0.00707262 
0.00118371 
0.00382993 
0.000752284 
0.000546992 
0.000831805 
0.000567544 
8.3755e-05 
0.000691767 
0.00978494 
0.00132202 
0.000546206 
0.000800936 
0.000290103 
0.00193157 
0.00419827 
0.00212783 
0.000990246 
0.000629074 
0.000999804 
0.00136602 
0.000982556 
0.00109725 
0.000509462 
0.000473291 
0.000491435 
0.000678729 
0.000479814 
0.000546615 
0.000754679 
0.000729916 
0.000728435 
0.000506531 
0.000658085 
0.0020362 
0.00103679 
0.00124391 
0.0017693 
0.000656421 
0.00294347 
0.00158394 
0.000958078 
0.000486301 
0.00164474 
0.0011634 
0.000449423 
0.000402865 
0.00015828 
0.00062443 
0.00062271 
0.00236713 
0.000714987 
0.00127927 
0.000122205 
0.000838005 
0.00601301 
0.000342771 
0.000562983 
0.00103821 
0.000839408 
0.000462973 
0.00149111 
0.00247137 
0.000590008 
0.00149145 
0.00129896 
0.00083355 
0.000927191 
0.000938219 
0.000721506 
0.000665867 
0.000183634 
0.000313292 
0.000298203 
0.00455202 
0.00200254 
0.000704722 
0.000140332 
0.000659525 
0.00262431 
0.00325091 
0.000869693 
0.000924282 
0.00500264 
0.00133171 
0.00232038 
4.35522e-05 
8.22575e-05 
0.00263134 
0.00176715 
0.00017646 
0.000956621 
0.00132516 
0.00126325 
0.00124796 
0.000619051 
0.00140785 
0.00086242 
0.00151868 
6.6961e-05 
0.00240583 
0.00269258 
0.000970534 
0.00404577 
0.000770182 
0.00158495 
0.000574735 
0.000429806 
0.00156472 
0.00503038 
0.000868986 
0.00115109 
0.00137502 
0.00013936 
0.000230072 
0.000702867 
0.000554257 
0.00149281 
0.000155893 
0.000651372 
7.89815e-05 
0.000127647 
5.89832e-05 
0.00135006 
0.00100021 
0.000544312 
0.000853639 
0.000513837 
0.00242727 
0.000983779 
0.000374075 
0.000512264 
0.000640015 
0.000431614 
0.0001495 
0.000703458 
0.00132899 
0.00301123 
0.000854995 
0.00181173 
0.00271784 
0.00035874 
0.000239589 
0.00497486 
0.000963848 
0.000329787 
0.000419054 
0.00170218 
0.000130342 
0.000861697 
0.00306105 
0.000606299 
0.0024072 
0.00107815 
0.000663704 
0.000413483 
0.000688854 
0.00136186 
0.000822951 
0.00131206 
0.00109937 
0.000379916 
0.000526882 
0.000373889 
0.00172756 
0.00194369 
0.000643017 
0.00167373 
0.000847682 
0.000380353 
0.000823815 
0.0015801 
0.00011519 
0.000764064 
0.000482491 
0.000481141 
0.000635514 
0.000470944 
0.00187498 
0.000874614 
0.00106677 
0.000370079 
0.00036676 
0.00128287 
0.00142395 
0.000761306 
0.00255828 
0.0040341 
0.000852763 
0.000728712 
0.00105438 
0.00163426 
0.000626858 
0.00144306 
0.000214111 
0.00172041 
0.00180644 
0.000214869 
0.0027474 
0.000219819 
0.000402193 
0.00129025 
0.000890811 
0.000296689 
0.000985939 
0.000562653 
0.000237483 
0.000630263 
0.00289763 
0.00151927 
0.000889057 
0.000872515 
0.00052174 
0.000581669 
0.00413511 
0.00129064 
0.000297964 
0.000471398 
0.000330268 
0.00155603 
0.000502463 
0.0016829 
0.000617801 
0.000869825 
0.000556241 
0.00128094 
0.000623488 
0.000336855 
0.000600977 
0.00352305 
0.000586702 
0.000935524 
0.00105049 
0.000713974 
0.000700041 
0.000213158 
0.0012295 
0.00221089 
0.00114164 
0.000650135 
0.001092 
0.00064314 
0.000471327 
0.000247212 
0.000424925 
9.3466e-05 
0.00160087 
0.000386881 
0.00365315 
0.00150322 
0.00117393 
3.24531e-05 
0.00100779 
0.00129734 
0.00104922 
0.000932412 
0.000606722 
0.000523737 
0.00173141 
0.000510538 
0.000438767 
0.000252378 
0.000330112 
0.00198047 
0.0015496 
0.000322265 
0.00013341 
0.000351882 
0.0013943 
0.000679309 
0.000689748 
0.000188377 
0.000105047 
0.000719788 
0.00132545 
0.000315474 
0.000682195 
4.79753e-05 
0.000267242 
0.000426501 
0.000363256 
0.000687793 
0.000662443 
0.000832573 
0.000222682 
0.00126341 
0.000629471 
0.000770224 
0.000418172 
0.000618414 
0.000793962 
8.72124e-05 
0.000508482 
0.00111502 
0.0020574 
0.000509427 
0.000196605 
0.000306182 
0.000331427 
0.000487137 
8.56628e-05 
0.00057442 
0.00135948 
0.000130254 
0.000861906 
0.000686281 
4.00089e-05 
0.000358011 
0.000873434 
0.000430541 
0.000209517 
0.000116366 
0.00165711 
0.000163761 
0.000946228 
0.000780059 
0.000380793 
0.00145142 
3.75345e-05 
0.0016259 
0.000465788 
0.000464026 
0.000411438 
3.38052e-05 
0.000186894 
0.00100873 
0.00126486 
0.000540524 
0.000778636 
0.000514196 
0.00120078 
0.000519637 
6.3904e-05 
0.000506037 
2.37371e-05 
0.000514735 
0.000549727 
0.000638086 
0.000418421 
0.00162737 
0.000823604 
0.000550713 
0.00010582 
0.00058887 
0.000440799 
0.000126743 
0.00017497 
4.75635e-05 
0.000407535 
0.00252209 
0.000368615 
0.000927727 
0.000307196 
2.57908e-05 
0.000804283 
5.2425e-05 
0.000176757 
0.000474809 
0.00101587 
0.000275532 
0.000198333 
0.000368127 
0.000277128 
0.000194176 
0.000438976 
0.00076904 
0.000727028 
0.00121906 
0.000193238 
0.00117239 
0.000252833 
9.16636e-05 
0.000181944 
0.000566954 
0.000303597 
4.25229e-05 
0.000170057 
0.00046231 
3.24538e-05 
0.000223772 
0.000145506 
0.000468175 
0.000863756 
0.000167525 
2.96907e-05 
0.000189148 
0.0002638 
0.000488405 
0.000207254 
2.92887e-05 
0.000224822 
0.000767929 
0.000466172 
0.000119489 
0.00025906 
0.000200073 
0.00179294 
0.000205503 
0.000126717 
0.000182261 
0.000124379 
0.000257439 
5.68259e-05 
0.000113119 
0.000161124 
0.000110922 
0.000226644 
3.45362e-05 
9.64843e-05 
0.000174658 
0.000295647 
0.000404356 
4.56358e-05 
0.000181469 
0.000474428 
0.00031262 
0.000162679 
0.000548984 
0.000730104 
0.00018707 
0.000242401 
0.000315443 
0.000536509 
0.000117607 
6.83271e-05 
0.00012119 
0.000772005 
0.000112271 
0.000247581 
9.07392e-05 
0.000100127 
4.21698e-05 
2.10112e-05 
0.000107947 
0.000204454 
0.000118555 
0.000152643 
3.7837e-05 
0.000375263 
7.28984e-05 
0.000275733 
0.000126712 
0.000812771 
0.000209238 
3.73572e-05 
7.74903e-05 
4.25235e-05 
0.000415942 
0.000174722 
0.000114674 
5.45032e-05 
0.000117337 
0.000196821 
6.71585e-05 
9.02825e-05 
0.000108913 
0.000158906 
0.00023784 
3.07303e-05 
3.96551e-05 
0.000311995 
0.000139619 
0.000258204 
0.000131015 
0.00020942 
0.000113348 
3.3395e-05 
0.000111199 
0.000169502 
8.16708e-05 
3.37999e-05 
2.94528e-05 
4.82105e-05 
6.01575e-05 
7.80442e-05 
2.84693e-05 
3.542e-05 
3.67981e-05 
0.000112948 
# Learning phase...
 - Before training
Accuracy: 174350/220551 = 0.79052
Average error toward 0: -1.44926e-05 (4009)
Average error toward 1: 0.000245023 (42192)
Prev: 0.791917 (error: 0.0181772) Offset: 0 0
Ratio error 1 : 0.913227
-----------------
- 41884 - 42192 - 
-----------------
- 4009 - 132466 - 
-----------------
 - Phase 1
Accuracy: 211438/220551 = 0.958681
Average error toward 0: -0.000015 (3861)
Average error toward 1: 0.000246 (5252)
Prev: 0.791917 (error: 0.017506) Offset: 0.000000 0.000000
Ratio error 1 : 0.576320
-----------------
- 42032 - 5252 - 
-----------------
- 3861 - 169406 - 
-----------------
 - Verification
Accuracy: 212154/220551 = 0.961927
Average error toward 0: -0.000015 (3927)
Average error toward 1: 0.000246 (4470)
Prev: 0.791917 (error: 0.017805) Offset: 0.000000 0.000000
Ratio error 1 : 0.532333
-----------------
- 41966 - 4470 - 
-----------------
- 3927 - 170188 - 
-----------------
Serialization of post-training strength vectors...
# Predictions
# Already in case-base: 21244 0.999953
0.957323
Accuracy: 24164/24505 = 0.986084
Average error toward 0: -0.000000 (122)
Average error toward 1: 0.000000 (219)
Prev: 0.791917 (error: 0.000553) Offset: 0.000000 0.000000
Ratio error 1 : 0.642229
-----------------
- 4844 - 219 - 
-----------------
- 122 - 19320 - 
-----------------
# Prediction serialization...
# Saving the [24505,768] weight matrix...
55.145413
